{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c5559-4b80-4a1e-851b-ca1cb50c33f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb82d97f-66a1-4e6d-9566-828d4e67e9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f39868c5-1164-4d43-be50-e6fc729c88f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# config\n",
    "_RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc79784b-1f8f-4ebf-b6a3-85f8b9f6e886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "from itertools import pairwise\n",
    "import collections\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "456eccd0-57c2-4f8c-a009-0d794fe7ef92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import automutualinformation\n",
    "import pickle\n",
    "\n",
    "context_dict = {\n",
    "    0:'Unknown',\n",
    "    1:'Separation',\n",
    "    2:'Biting',\n",
    "    3:'Feeding',\n",
    "    4:'Fighting',\n",
    "    5:'Grooming',\n",
    "    6:'Isolation',\n",
    "    7:'Kissing',\n",
    "    8:'Landing',\n",
    "    9:'Mating protest',\n",
    "    10:'Threat-like',\n",
    "    11:'General',\n",
    "    12:'Sleeping',\n",
    "}\n",
    "\n",
    "\n",
    "def load_seq_data( dataset_descriptor, number_of_clusters):\n",
    "    # Load The Sequences!\n",
    "    with open(f'symbolic_sequences_{dataset_descriptor}_{number_of_clusters}_symseq.pkl','rb') as f:\n",
    "        symbolic_sequences = pickle.load(f)\n",
    "\n",
    "    # Load The Graph!\n",
    "    with open(f'graph_symbolic_sequences_{dataset_descriptor}_{number_of_clusters}_graphsymseq.pkl','rb') as f:\n",
    "        G = pickle.load(f)\n",
    "\n",
    "    # Load The Sequences!\n",
    "    with open(f\"{dataset_descriptor}_{number_of_clusters}_map_complete.pkl\",'rb') as f:\n",
    "        seq_mapped = pickle.load(f)\n",
    "        seq_mapped.drop_duplicates(subset=[\"voc_segments_ix\"], keep=\"first\", inplace=True)\n",
    "        seq_mapped.index = range(len(seq_mapped.index))\n",
    "        seq_mapped.index.set_names('segmentID', inplace=True)\n",
    "        \n",
    "    return symbolic_sequences, G, seq_mapped\n",
    "    \n",
    "#symbolic_sequences_offspring, G_offspring, seq_mapped_offspring = load_seq_data( 'offspring_relationships', 372)\n",
    "#symbolic_sequences_wildbats, G_wildbats, seq_mapped_wildbats = load_seq_data( 'wildbats_relationships', 175 )\n",
    "symbolic_sequences_bat_215, G_bat_215, seq_mapped_bat_215 = load_seq_data( 'bat_215', 84 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85b9d84a-5f18-43bc-acba-2a404116df50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CHOOSE THE DB\n",
    "\n",
    "#seg_mapped = seq_mapped_offspring\n",
    "#symbolic_sequences = symbolic_sequences_offspring\n",
    "\n",
    "symbolic_sequences = symbolic_sequences_bat_215\n",
    "seq_mapped = seq_mapped_bat_215"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7decde7-5c58-478e-abb9-c5631267ce3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "776cdc29-eb95-4c19-beb3-14d05106387e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbolic_sequences['context'] = symbolic_sequences['label_context'].apply(lambda x : collections.Counter(x).most_common()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "48938bc5-5735-4a88-a852-a03fe6818976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import pairwise\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# unigrams\n",
    "_1_gram = symbolic_sequences['Seq_Syllables'].explode().value_counts().to_dict()\n",
    "_1_gram = {k : v/ sum(_1_gram.values()) for k, v in _1_gram.items()}\n",
    "\n",
    "# bigrams\n",
    "_2_gram = pd.Series([p for seq in symbolic_sequences['Seq_Syllables'] for p in pairwise(seq)]).value_counts().to_dict()\n",
    "_2_gram = {k : v/ sum(_2_gram.values()) for k, v in _2_gram.items()}\n",
    "\n",
    "#_3_gram = symbolic_sequences['Seq_Syllables'].apply(lambda seq: tuple(seq[i: i + 3] for i in range(len(seq) - 3 + 1))).explode().value_counts().to_dict()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6bf907f1-1513-4389-b80f-1aef03854aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4069350/1792106621.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _2_gram = pd.Series([p for seq in tmp_series for p in pairwise(seq)]).value_counts().to_dict()\n"
     ]
    }
   ],
   "source": [
    "# depending on context:\n",
    "\n",
    "_grams = {}\n",
    "\n",
    "for context in symbolic_sequences['context']:\n",
    "    \n",
    "    tmp_series = symbolic_sequences[symbolic_sequences['context'] == context]['Seq_Syllables']\n",
    "    \n",
    "    _1_gram = tmp_series.explode().value_counts().to_dict()\n",
    "    _1_gram = {k : v/ sum(_1_gram.values()) for k, v in _1_gram.items()}\n",
    "    \n",
    "    _2_gram = pd.Series([p for seq in tmp_series for p in pairwise(seq)]).value_counts().to_dict()\n",
    "    _2_gram = {k : v/ sum(_2_gram.values()) for k, v in _2_gram.items()}\n",
    "    \n",
    "    _grams[context] = {\n",
    "            '_1_gram' : _1_gram,\n",
    "            '_2_gram' : _2_gram,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "197c4e03-f947-4643-bf6a-a6b5bc63f424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_grams;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6de82d7c-aa5e-451c-92df-34c52fb50450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conditional_p(antecedent, current,  _1_gram_voc = _1_gram, _2_gram_voc = _2_gram):\n",
    "    \n",
    "    # forward transitional probability\n",
    "    #https://corpustools.readthedocs.io/en/latest/transitional_probability.html\n",
    "    \n",
    "    #given the order: xy => p(y|x) = p(xy )/ p(x)\n",
    "    try:\n",
    "        # p(y|x) = p(xy )/ p(x)\n",
    "        prob = _2_gram_voc[(antecedent, current)] / _1_gram_voc[(antecedent)]\n",
    "    except KeyError:\n",
    "        prob = 1\n",
    "            \n",
    "    return prob\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f4ce0143-0a2e-48aa-9b78-674374e7f219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transitional_p(current, successor , _1_gram_voc = _1_gram, _2_gram_voc = _2_gram):\n",
    "    \n",
    "    #backword transitional probability\n",
    "    #https://corpustools.readthedocs.io/en/latest/transitional_probability.html\n",
    "    \n",
    "    #given the order: xy => p(x|y) = p(xy )/ p(y)\n",
    "    \n",
    "    try:\n",
    "        prob = _2_gram_voc[(current, successor)] / _1_gram_voc[(successor)]\n",
    "    except KeyError:\n",
    "        prob = 1\n",
    "            \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cf9cf628-f184-463c-b950-dc3e921678ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transitional_p'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitional_p.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1090f9f0-6613-40c3-9996-a125f25638d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def p_seq(seq, probability_function, vocabularies = [_1_gram, _2_gram]):  \n",
    "    \n",
    "    _1_gram_voc = vocabularies[0]\n",
    "    _2_gram_voc = vocabularies[1]\n",
    "    \n",
    "    prob = 1.\n",
    "    \n",
    "    initial_p = seq[0]\n",
    "    \n",
    "    prob *= initial_p\n",
    "\n",
    "    for p in pairwise(seq[1:]):    \n",
    "        \n",
    "        \n",
    "        \n",
    "        antecedent = p[0]\n",
    "        current = p[1]\n",
    "        \n",
    "        if probability_function.__name__ == 'conditional_p':\n",
    "\n",
    "            prob *= probability_function(antecedent, current, _1_gram_voc = _1_gram_voc, _2_gram_voc = _2_gram_voc )\n",
    "\n",
    "        elif probability_function.__name__ == 'transitional_p':\n",
    "\n",
    "            prob *= probability_function(antecedent, current, _1_gram_voc = _1_gram_voc, _2_gram_voc = _2_gram_voc)\n",
    "\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "322f231d-4ab2-4e01-a220-94f47132878a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter([0,1]).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "47eb023c-83c4-4332-869a-df144a3577c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def syl_in_seq(seq):\n",
    "    return sum( collections.Counter(seq).values() )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "97e5b93d-590d-4edb-8edf-a606aedfd603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy_seq(seq, vocabulary = _1_gram):\n",
    "    \n",
    "    entropy = 0\n",
    "    \n",
    "    for syl in seq:\n",
    "        try:\n",
    "            prob =  vocabulary[syl] / len(vocabulary)\n",
    "        except KeyError:\n",
    "            prob = 0\n",
    "        \n",
    "        entropy += -prob * np.log2(prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "500f7018-b3d1-4954-8a5a-8f8d77a5a471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3.078513e-01\n",
       "1       3.078513e-01\n",
       "2       1.000000e+00\n",
       "3       4.586987e-01\n",
       "4       1.000000e+00\n",
       "            ...     \n",
       "6074    5.794988e-66\n",
       "6075    3.029826e-36\n",
       "6076    1.509544e-04\n",
       "6077    8.443615e-57\n",
       "6078    2.159375e-09\n",
       "Name: Seq_Syllables, Length: 6079, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_sequences['Seq_Syllables'].apply(lambda x : p_seq(x, transitional_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e673f917-acde-4a89-848f-3c24e53f2501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_1_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "86139367-e4d5-437c-85e5-41321d738739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbolic_sequences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8afe8dbe-df37-4c64-9684-f9afc471cd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(sequences_series):\n",
    "    \n",
    "    columns = ['entropy', 'conditional', 'transitional']\n",
    "    \n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    df['syl_in_seq'] = sequences_series.apply(syl_in_seq)\n",
    "    df['entropy'] = sequences_series.apply(entropy_seq)\n",
    "    df['conditional'] = sequences_series.apply(lambda x : p_seq(x, conditional_p))\n",
    "    df['transitional'] = sequences_series.apply(lambda x : p_seq(x, transitional_p))\n",
    "    \n",
    "    for k in _grams:\n",
    "        vocabularies = [_grams[k]['_1_gram'], _grams[k]['_2_gram']]\n",
    "        df[f'entropy_{k}'] = sequences_series.apply(lambda x : entropy_seq(x , vocabulary = vocabularies[0] ))\n",
    "        df[f'conditional_{k}'] = sequences_series.apply(lambda x : p_seq(x , conditional_p, vocabularies = vocabularies))\n",
    "        df[f'transitional_{k}'] = sequences_series.apply(lambda x : p_seq(x , transitional_p, vocabularies = vocabularies))\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "43f9ed54-c222-4e4e-b595-7d9aa4b250a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>conditional</th>\n",
       "      <th>transitional</th>\n",
       "      <th>syl_in_seq</th>\n",
       "      <th>entropy_6</th>\n",
       "      <th>conditional_6</th>\n",
       "      <th>transitional_6</th>\n",
       "      <th>entropy_12</th>\n",
       "      <th>conditional_12</th>\n",
       "      <th>transitional_12</th>\n",
       "      <th>...</th>\n",
       "      <th>transitional_7</th>\n",
       "      <th>entropy_8</th>\n",
       "      <th>conditional_8</th>\n",
       "      <th>transitional_8</th>\n",
       "      <th>entropy_10</th>\n",
       "      <th>conditional_10</th>\n",
       "      <th>transitional_10</th>\n",
       "      <th>entropy_5</th>\n",
       "      <th>conditional_5</th>\n",
       "      <th>transitional_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>2.661083</td>\n",
       "      <td>5.569905e-37</td>\n",
       "      <td>7.103762e-38</td>\n",
       "      <td>51</td>\n",
       "      <td>0.289441</td>\n",
       "      <td>8.124146e-09</td>\n",
       "      <td>6.743602e-13</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>1.183920e-37</td>\n",
       "      <td>1.484887e-35</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411947e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.644132</td>\n",
       "      <td>1.527646e-10</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.565092</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.048023e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>1.863402</td>\n",
       "      <td>2.331523e-05</td>\n",
       "      <td>2.331523e-05</td>\n",
       "      <td>24</td>\n",
       "      <td>0.289441</td>\n",
       "      <td>1.896300e-08</td>\n",
       "      <td>5.735501e-10</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>2.941155e-07</td>\n",
       "      <td>2.941155e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.999839e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.594532</td>\n",
       "      <td>3.685894e-05</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.565092</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>3.518366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>0.277605</td>\n",
       "      <td>3.634551e+00</td>\n",
       "      <td>2.849772e+01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.382329</td>\n",
       "      <td>1.419211e+01</td>\n",
       "      <td>1.419211e+01</td>\n",
       "      <td>0.231358</td>\n",
       "      <td>3.856210e+00</td>\n",
       "      <td>2.451507e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.874733e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.844808</td>\n",
       "      <td>2.877587e+00</td>\n",
       "      <td>19.688756</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>7.897274</td>\n",
       "      <td>3.079937e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>2.440229</td>\n",
       "      <td>3.218542e-22</td>\n",
       "      <td>3.218542e-22</td>\n",
       "      <td>40</td>\n",
       "      <td>0.289441</td>\n",
       "      <td>5.270535e-10</td>\n",
       "      <td>1.446454e-12</td>\n",
       "      <td>2.016862</td>\n",
       "      <td>1.145707e-22</td>\n",
       "      <td>4.433631e-25</td>\n",
       "      <td>...</td>\n",
       "      <td>7.280492e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.644132</td>\n",
       "      <td>7.384862e-12</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.565092</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.457369e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.609308</td>\n",
       "      <td>1.712275e+01</td>\n",
       "      <td>1.712275e+01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>5.087722e-02</td>\n",
       "      <td>5.087722e-02</td>\n",
       "      <td>0.502661</td>\n",
       "      <td>8.831951e+00</td>\n",
       "      <td>8.831951e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.960300e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.819685</td>\n",
       "      <td>1.586289e+01</td>\n",
       "      <td>15.862894</td>\n",
       "      <td>1.661222</td>\n",
       "      <td>4.101705</td>\n",
       "      <td>4.101705e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entropy   conditional  transitional  syl_in_seq  entropy_6  \\\n",
       "6074  2.661083  5.569905e-37  7.103762e-38          51   0.289441   \n",
       "6075  1.863402  2.331523e-05  2.331523e-05          24   0.289441   \n",
       "6076  0.277605  3.634551e+00  2.849772e+01           4   0.382329   \n",
       "6077  2.440229  3.218542e-22  3.218542e-22          40   0.289441   \n",
       "6078  0.609308  1.712275e+01  1.712275e+01           7   0.822775   \n",
       "\n",
       "      conditional_6  transitional_6  entropy_12  conditional_12  \\\n",
       "6074   8.124146e-09    6.743602e-13    0.213887    1.183920e-37   \n",
       "6075   1.896300e-08    5.735501e-10    1.540247    2.941155e-07   \n",
       "6076   1.419211e+01    1.419211e+01    0.231358    3.856210e+00   \n",
       "6077   5.270535e-10    1.446454e-12    2.016862    1.145707e-22   \n",
       "6078   5.087722e-02    5.087722e-02    0.502661    8.831951e+00   \n",
       "\n",
       "      transitional_12  ...  transitional_7  entropy_8  conditional_8  \\\n",
       "6074     1.484887e-35  ...    2.411947e-10        0.0           58.0   \n",
       "6075     2.941155e-07  ...    5.999839e-05        0.0           58.0   \n",
       "6076     2.451507e+01  ...    2.874733e+01        0.0           58.0   \n",
       "6077     4.433631e-25  ...    7.280492e-11        0.0           58.0   \n",
       "6078     8.831951e+00  ...    1.960300e+01        0.0           58.0   \n",
       "\n",
       "      transitional_8  entropy_10  conditional_10  transitional_10  entropy_5  \\\n",
       "6074            58.0    0.644132    1.527646e-10         0.000003   0.565092   \n",
       "6075            58.0    5.594532    3.685894e-05         0.004792   0.565092   \n",
       "6076            58.0    0.844808    2.877587e+00        19.688756   0.801827   \n",
       "6077            58.0    0.644132    7.384862e-12         0.000045   0.565092   \n",
       "6078            58.0    1.819685    1.586289e+01        15.862894   1.661222   \n",
       "\n",
       "      conditional_5  transitional_5  \n",
       "6074       0.000005    5.048023e-06  \n",
       "6075       0.000352    3.518366e-04  \n",
       "6076       7.897274    3.079937e+01  \n",
       "6077       0.000011    2.457369e-07  \n",
       "6078       4.101705    4.101705e+00  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_1 = symbolic_sequences.label_context.apply(lambda x : len(np.unique(x)) < 2)\n",
    "cond_2 = symbolic_sequences.label_context.apply(lambda x : all(i in [9, 2, 3,6, 4, 7, 5, 10] for i in x))\n",
    "\n",
    "raw_data = symbolic_sequences.loc[cond_1 & cond_2];\n",
    "\n",
    "X = prepare_data(raw_data['Seq_Syllables']);\n",
    "\n",
    "X = X.fillna(X.mean(axis=0))\n",
    "\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c9d868a9-b800-40dd-a8da-24f3aae565db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = raw_data['label_context'].apply(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b7d7ff11-47e1-4231-86f2-60b411a78988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 8)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state= _RANDOM_STATE)\n",
    "\n",
    "# training, validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.25, random_state= _RANDOM_STATE)\n",
    "\n",
    "# binarise the classes \n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_val = label_binarizer.transform(y_val)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bad9ba69-c970-477b-a9ec-e089418517b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Scale the features\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_val_std = sc.transform(X_val)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# test permutation\n",
    "#X_permuted_std = sc.transform(X_perm)\n",
    "#y_permuted = permuted_pruned_df.iloc[X_test.index]['label_context'].apply(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de7faf53-3a61-4ae9-a4bf-f32890e4bb32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 152\n",
      "Accuracy: 0.53\n",
      "Precision: 0.53\n",
      "Recall: 0.53\n",
      "F1-micro: 0.53\n",
      "F1-weighted: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=100, random_state=_RANDOM_STATE, n_jobs=-1)\n",
    "forest.fit(X_train_std, y_train)\n",
    "y_pred = forest.predict(X_test_std)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print('Precision: %.2f' % precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Recall: %.2f' % recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('F1-micro: %.2f' % f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('F1-weighted: %.2f' % f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2433401a-f1b6-4e2d-beaa-4b95a1ed60a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy_11 0.06317620005606922\n",
      "entropy 0.05060204368981685\n",
      "entropy_4 0.048556831617663714\n",
      "entropy_12 0.04326459615364474\n",
      "conditional_6 0.03980834584999589\n",
      "entropy_9 0.039788463111450845\n",
      "entropy_3 0.0389416260360765\n",
      "entropy_2 0.036956072936662414\n",
      "transitional_7 0.02918709753397129\n",
      "transitional_8 0.02833794351615929\n",
      "conditional_10 0.027279246818265355\n",
      "entropy_10 0.027243251462768552\n",
      "conditional_5 0.027216050636608858\n",
      "transitional_11 0.027147243719406158\n",
      "entropy_6 0.026233243412101242\n",
      "transitional_2 0.025702631817772523\n",
      "transitional_5 0.02514754964727888\n",
      "conditional_8 0.02434458521361713\n",
      "entropy_7 0.024171547498720285\n",
      "transitional_10 0.023699580650591332\n",
      "conditional_3 0.023515598265346525\n",
      "transitional_3 0.023299387489882747\n",
      "conditional_11 0.02295833763798585\n",
      "entropy_5 0.022449074619853165\n",
      "conditional_7 0.022281975750283015\n",
      "conditional_4 0.02223887107452554\n",
      "transitional_4 0.022124037186014876\n",
      "conditional_9 0.021535184700590394\n",
      "conditional_2 0.021180088223810255\n",
      "transitional_6 0.02096403082765516\n",
      "conditional_12 0.019595425348699378\n",
      "transitional_12 0.018356188227965833\n",
      "conditional 0.017542616649137317\n",
      "syl_in_seq 0.01548368522456023\n",
      "transitional_9 0.01522755459328711\n",
      "transitional 0.014443792801761718\n",
      "entropy_8 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_labels = X.columns\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(feature_labels[indices[f]], importances[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e7774d90-44d7-4696-bc75-a2001daf578b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Biting       0.42      0.15      0.22        72\n",
      "       Feeding       0.20      0.04      0.07        24\n",
      "      Fighting       0.00      0.00      0.00        13\n",
      "      Grooming       0.00      0.00      0.00        12\n",
      "     Isolation       1.00      0.80      0.89        20\n",
      "       Kissing       0.00      0.00      0.00        12\n",
      "Mating protest       0.53      0.90      0.66       157\n",
      "   Threat-like       0.00      0.00      0.00        11\n",
      "\n",
      "      accuracy                           0.53       321\n",
      "     macro avg       0.27      0.24      0.23       321\n",
      "  weighted avg       0.43      0.53      0.44       321\n",
      "\n",
      "[[ 11   1   0   1   0   0  59   0]\n",
      " [  2   1   0   0   0   0  21   0]\n",
      " [  0   0   0   0   0   0  13   0]\n",
      " [  0   0   0   0   0   0  12   0]\n",
      " [  1   1   0   0  16   0   2   0]\n",
      " [  1   1   0   0   0   0  10   0]\n",
      " [ 11   0   2   3   0   0 141   0]\n",
      " [  0   1   0   0   0   0  10   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/home/h21/luas6629/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data0/home/h21/luas6629/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data0/home/h21/luas6629/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,\n",
    "                            y_pred,\n",
    "                            digits=2, \n",
    "                            target_names= [context_dict[i] for i in [2,3,4,5,6,7,9,10]]\n",
    "                           )\n",
    "     )\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assuming y_true and y_pred are your true and predicted labels, respectively\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c29638-922d-4d4c-9fdb-1b9f0bdb3a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
