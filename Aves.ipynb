{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bd0f16-3a2a-4856-990f-e250a140fbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e601c7af-0d56-4e13-b7b6-c5c07ffdfb9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import automutualinformation\n",
    "import pickle\n",
    "\n",
    "# Load The Sequences!\n",
    "with open('symbolic_sequences_pup2mother_All.bkp.pkl','rb') as f:\n",
    "    symbolic_sequences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5889d9cf-f6db-4af9-8332-0596d3a9de20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_DIR set on:  /data0/home/h21/luas6629/Thesis\n"
     ]
    }
   ],
   "source": [
    "# wrapper lib\n",
    "from avgn.utils.paths import DATA_DIR, ensure_dir\n",
    "from pathlib2 import Path\n",
    "\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "DSLOC = DATA_DIR / 'raw' / 'fruitbat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5cbdc2-cd0c-4580-8a2c-3c361c8bdf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/raw/fruitbat')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSLOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77805b86-bb8d-4bf0-b310-d93cf9a06c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load( DSLOC / 'zip_contents'/ 'files101' /  '120601000005102988.WAV'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37e1b8f-b301-4a72-8af7-86cb1c470d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbolic_sequences['Path'] =  './data/raw/fruitbat/zip_contents/' + symbolic_sequences['Folder'] +'/' + symbolic_sequences['File name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96ddbfd9-68f4-45dc-8d01-4bb04ccb8360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbolic_sequences['waveform'] = symbolic_sequences['Path'].apply(lambda x  : torchaudio.load(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5da3900-8c8c-4e6e-b3b2-38545cf0194e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File name</th>\n",
       "      <th>Seq_Syllables</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Folder</th>\n",
       "      <th>labels.label_addressee</th>\n",
       "      <th>labels.label_context</th>\n",
       "      <th>Path</th>\n",
       "      <th>waveform_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121002212651151905.WAV</td>\n",
       "      <td>[8, 2, 9]</td>\n",
       "      <td>[28341, 19373, 28746]</td>\n",
       "      <td>files201</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>./data/raw/fruitbat/zip_contents/files201/1210...</td>\n",
       "      <td>[[tensor(-0.0002), tensor(-0.0005), tensor(0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121003075445185924.WAV</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[26746]</td>\n",
       "      <td>files201</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>./data/raw/fruitbat/zip_contents/files201/1210...</td>\n",
       "      <td>[[tensor(3.0518e-05), tensor(-3.0518e-05), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121004173718193940.WAV</td>\n",
       "      <td>[9, 9, 9]</td>\n",
       "      <td>[26773, 27746, 25246]</td>\n",
       "      <td>files201</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>./data/raw/fruitbat/zip_contents/files201/1210...</td>\n",
       "      <td>[[tensor(-0.0008), tensor(0.0008), tensor(0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121005221219635013.WAV</td>\n",
       "      <td>[7, 9, 9]</td>\n",
       "      <td>[26756, 36746, 39246]</td>\n",
       "      <td>files202</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>./data/raw/fruitbat/zip_contents/files202/1210...</td>\n",
       "      <td>[[tensor(-3.0518e-05), tensor(-0.0003), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121006093630175196.WAV</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[28746]</td>\n",
       "      <td>files202</td>\n",
       "      <td>[209]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>./data/raw/fruitbat/zip_contents/files202/1210...</td>\n",
       "      <td>[[tensor(0.0003), tensor(-0.0006), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File name Seq_Syllables               Duration    Folder  \\\n",
       "0  121002212651151905.WAV     [8, 2, 9]  [28341, 19373, 28746]  files201   \n",
       "1  121003075445185924.WAV           [9]                [26746]  files201   \n",
       "2  121004173718193940.WAV     [9, 9, 9]  [26773, 27746, 25246]  files201   \n",
       "3  121005221219635013.WAV     [7, 9, 9]  [26756, 36746, 39246]  files202   \n",
       "4  121006093630175196.WAV           [9]                [28746]  files202   \n",
       "\n",
       "  labels.label_addressee labels.label_context  \\\n",
       "0                  [209]                  [6]   \n",
       "1                  [209]                  [6]   \n",
       "2                  [209]                  [6]   \n",
       "3                  [209]                  [6]   \n",
       "4                  [209]                  [6]   \n",
       "\n",
       "                                                Path  \\\n",
       "0  ./data/raw/fruitbat/zip_contents/files201/1210...   \n",
       "1  ./data/raw/fruitbat/zip_contents/files201/1210...   \n",
       "2  ./data/raw/fruitbat/zip_contents/files201/1210...   \n",
       "3  ./data/raw/fruitbat/zip_contents/files202/1210...   \n",
       "4  ./data/raw/fruitbat/zip_contents/files202/1210...   \n",
       "\n",
       "                                        waveform_col  \n",
       "0  [[tensor(-0.0002), tensor(-0.0005), tensor(0.0...  \n",
       "1  [[tensor(3.0518e-05), tensor(-3.0518e-05), ten...  \n",
       "2  [[tensor(-0.0008), tensor(0.0008), tensor(0.00...  \n",
       "3  [[tensor(-3.0518e-05), tensor(-0.0003), tensor...  \n",
       "4  [[tensor(0.0003), tensor(-0.0006), tensor(-0.0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49722f10-4e77-4de6-b447-6b21c73eee52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self, dataframe, waveform_col, label_col, transform=None):\n",
    "        \"\"\"\n",
    "        Custom PyTorch dataset for waveform data with multiple labels.\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): Input dataframe that contains waveform data and labels.\n",
    "            waveform_col (str): Name of the column in the dataframe that contains waveform data.\n",
    "            label_col (str): Name of the column in the dataframe that contains label data.\n",
    "            transform (callable, optional): Optional data transformation function to be applied to the waveforms.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.waveform_col = waveform_col\n",
    "        self.label_col = label_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform = self.dataframe.loc[index, self.waveform_col]  # Get waveform data at index\n",
    "        label = self.dataframe.loc[index, self.label_col]  # Get label data at index\n",
    "\n",
    "        # Apply data transformation if provided\n",
    "        if self.transform is not None:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5539ef1a-d8f3-4faf-817c-7c6777cd5f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AvesClassifier(nn.Module):\n",
    "    def __init__(self, model_path, num_classes, embeddings_dim=768, multi_label=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([model_path])\n",
    "        self.model = models[0]\n",
    "        self.model.feature_extractor.requires_grad_(False)\n",
    "        self.head = nn.Linear(in_features=embeddings_dim, out_features=num_classes)\n",
    "\n",
    "        if multi_label:\n",
    "            self.loss_func = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        out = self.model.extract_features(x)[0]\n",
    "        out = out.mean(dim=1)             # mean pooling\n",
    "        logits = self.head(out)\n",
    "\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = self.loss_func(logits, y)\n",
    "\n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cda6beb-1d64-4a4e-a63f-f5d48b3cb723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate WaveformDataset\n",
    "dataset = WaveformDataset(symbolic_sequences, 'waveform_col','labels.label_context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc939134-a042-48f3-97b7-286025f7e6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fairseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "def73bed-2ce1-42ea-a233-8ba5ca42b870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0002, -0.0005,  0.0008,  ...,  0.0010,  0.0003,  0.0003]]), ['6'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "842f06b5-24d1-486d-9285-0388e4ee959e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7562e7c6-b6ba-4c8b-939c-06f37b9afeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3d8b9b2-5b0f-42b8-a499-8488a2afe757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b295efc3-636b-409a-8ba6-959da8de59a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: fairseq 0.12.2\n",
      "Uninstalling fairseq-0.12.2:\n",
      "  Successfully uninstalled fairseq-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall fairseq -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69119d3d-f1ca-4430-9f37-c524b68234f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (1.15.1)\n",
      "Requirement already satisfied: torch in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (1.13.1)\n",
      "Requirement already satisfied: bitarray in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (2.7.3)\n",
      "Requirement already satisfied: omegaconf<2.1 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (2.0.6)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (0.13.1)\n",
      "Requirement already satisfied: numpy in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (1.23.5)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (1.0.7)\n",
      "Requirement already satisfied: regex in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (2022.10.31)\n",
      "Requirement already satisfied: cython in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (0.29.33)\n",
      "Requirement already satisfied: tqdm in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from fairseq) (4.64.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
      "Requirement already satisfied: typing-extensions in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
      "Requirement already satisfied: colorama in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
      "Requirement already satisfied: lxml in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
      "Requirement already satisfied: portalocker in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (2.7.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from torch->fairseq) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from torch->fairseq) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from torch->fairseq) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from torch->fairseq) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->fairseq) (59.6.0)\n",
      "Requirement already satisfied: wheel in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->fairseq) (0.38.4)\n",
      "Requirement already satisfied: pycparser in /data0/home/h21/luas6629/venv/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11162107 sha256=2d340ee640a5a1f1d2daed98eb5a17e63ebcb5fcefbaed57760182b05025f699\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j6nhxkhz/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
      "Successfully built fairseq\n",
      "Installing collected packages: fairseq\n",
      "Successfully installed fairseq-0.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairseq --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a66becd1-3a57-426f-9629-db98179fc52f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache contents:\n",
      "\n",
      " - antlr4_python3_runtime-4.8-py3-none-any.whl (141 kB)\n",
      " - datashape-0.5.2-py3-none-any.whl (59 kB)\n",
      " - fairseq-0.12.2-cp310-cp310-linux_x86_64.whl (11.2 MB)\n",
      " - fitter-1.5.2-py3-none-any.whl (25 kB)\n",
      " - future-0.18.3-py3-none-any.whl (492 kB)\n",
      " - hdbscan-0.8.29-cp310-cp310-linux_x86_64.whl (3.0 MB)\n",
      " - pathtools-0.1.2-py3-none-any.whl (8.8 kB)\n",
      " - pomegranate-0.14.8-cp310-cp310-linux_x86_64.whl (18.2 MB)\n",
      " - pyclustering-0.10.1.2-py3-none-any.whl (2.4 MB)\n",
      " - pynndescent-0.5.8-py3-none-any.whl (55 kB)\n",
      " - tinytag-1.8.1-py3-none-any.whl (36 kB)\n",
      " - umap_learn-0.5.3-py3-none-any.whl (82 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip3 cache list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5066f95-f9bd-40a5-8aca-1f5756c830dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'metrics' from 'fairseq' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'metrics' from 'fairseq' (unknown location)"
     ]
    }
   ],
   "source": [
    "from fairseq import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bfc94ef-5ea6-4de2-a9fe-616ca1c674fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'metrics' from 'fairseq' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_utils\u001b[39;00m\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/checkpoint_utils.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FSDP, has_FSDP\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PathManager\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqDecoder, FairseqEncoder\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConfig, OmegaConf, open_dict\n\u001b[1;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/models/__init__.py:235\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# automatically import any Python files in the models/ directory\u001b[39;00m\n\u001b[1;32m    234\u001b[0m models_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m--> 235\u001b[0m \u001b[43mimport_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfairseq.models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/models/__init__.py:217\u001b[0m, in \u001b[0;36mimport_models\u001b[0;34m(models_dir, namespace)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(path))\n\u001b[1;32m    215\u001b[0m ):\n\u001b[1;32m    216\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m file[: file\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m--> 217\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# extra `model_parser` for sphinx\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m MODEL_REGISTRY:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/models/transformer_ulm.py:20\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceEnum\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     FairseqLanguageModel,\n\u001b[1;32m     17\u001b[0m     register_model,\n\u001b[1;32m     18\u001b[0m     register_model_architecture,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeech_ulm_task\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpeechUnitLanguageModelingTask\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding, TransformerDecoder, Linear\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_lm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerLanguageModelConfig\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/tasks/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge_with_parent\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigStore\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfairseq_task\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqTask, LegacyFairseqTask  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# register dataclass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m TASK_DATACLASS_REGISTRY \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/data0/home/h21/luas6629/Thesis/fairseq/fairseq/tasks/fairseq_task.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics, search, tokenizer, utils\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary, FairseqDataset, data_utils, encoders, iterators\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqDataclass\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'metrics' from 'fairseq' (unknown location)"
     ]
    }
   ],
   "source": [
    "import fairseq.checkpoint_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11a4cbea-3bc3-4716-b566-6a099035d233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fairseq' has no attribute 'checkpoint_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate AvesClassifier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAvesClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./aves-base-bio.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mAvesClassifier.__init__\u001b[0;34m(self, model_path, num_classes, embeddings_dim, multi_label)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path, num_classes, embeddings_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m     models, cfg, task \u001b[38;5;241m=\u001b[39m \u001b[43mfairseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_utils\u001b[49m\u001b[38;5;241m.\u001b[39mload_model_ensemble_and_task([model_path])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fairseq' has no attribute 'checkpoint_utils'"
     ]
    }
   ],
   "source": [
    "# Instantiate AvesClassifier\n",
    "model = AvesClassifier(\n",
    "    model_path='./aves-base-bio.pt',\n",
    "    num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88a57ba9-f6ab-46b2-b158-e80fe01016e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mloss_func\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = model.loss_func\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ff7ee-a9db-4e24-ade9-7ccf9a8ec238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
